---
phase: 14-module-refactoring-runtime-integration
plan: 03
type: execute
wave: 3
depends_on: ["14-01", "14-02"]
files_modified:
  - src/OpenAnima.Core/DependencyInjection.cs
  - src/OpenAnima.Core/Components/Shared/ChatPanel.razor
  - tests/OpenAnima.Tests/Integration/E2EWiringTests.cs
autonomous: false
requirements: [E2E-01]

must_haves:
  truths:
    - "User can wire ChatInput→LLM→ChatOutput in editor and have a working conversation"
    - "Sending a message through ChatInputModule reaches LLMModule via port connection"
    - "LLM response flows from LLMModule to ChatOutputModule via port connection"
    - "Chat conversation behavior is identical to v1.2 (user sends message, gets LLM response)"
  artifacts:
    - path: "src/OpenAnima.Core/DependencyInjection.cs"
      provides: "Module DI registration (LLMModule, ChatInputModule, ChatOutputModule, HeartbeatModule)"
      contains: "AddSingleton.*LLMModule"
    - path: "tests/OpenAnima.Tests/Integration/E2EWiringTests.cs"
      provides: "End-to-end test: ChatInput→LLM→ChatOutput wiring"
      contains: "ChatInput_LLM_ChatOutput_Wiring"
  key_links:
    - from: "ChatInputModule"
      to: "LLMModule"
      via: "WiringEngine EventBus subscription routing userMessage→prompt"
      pattern: "ChatInputModule.*port.*userMessage.*LLMModule.*port.*prompt"
    - from: "LLMModule"
      to: "ChatOutputModule"
      via: "WiringEngine EventBus subscription routing response→displayText"
      pattern: "LLMModule.*port.*response.*ChatOutputModule.*port.*displayText"
    - from: "ChatPanel.razor"
      to: "ChatInputModule"
      via: "SendMessageAsync call on user submit"
      pattern: "ChatInputModule.*SendMessageAsync"
---

<objective>
Wire modules into DI, connect ChatPanel UI to ChatInputModule/ChatOutputModule, and verify end-to-end ChatInput→LLM→ChatOutput conversation flow matches v1.2 behavior.

Purpose: Achieve v1.2 feature parity through the new modular wiring architecture — user sends message, it flows through port connections to LLM and back to display.
Output: DI registration, ChatPanel integration, E2E integration test, visual checkpoint
</objective>

<execution_context>
@/home/user/.claude/get-shit-done/workflows/execute-plan.md
@/home/user/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-module-refactoring-runtime-integration/14-CONTEXT.md
@.planning/phases/14-module-refactoring-runtime-integration/14-RESEARCH.md
@.planning/phases/14-module-refactoring-runtime-integration/14-01-SUMMARY.md
@.planning/phases/14-module-refactoring-runtime-integration/14-02-SUMMARY.md

<interfaces>
<!-- Key types from Plan 01 and Plan 02 -->

From Plan 01 - Module implementations:
```csharp
// ChatInputModule has public method:
public async Task SendMessageAsync(string message, CancellationToken ct = default)
// Publishes to "{Metadata.Name}.port.userMessage"

// ChatOutputModule has public event:
public event Action<string>? OnMessageReceived;
public string? LastReceivedText { get; }

// LLMModule subscribes to "{Metadata.Name}.port.prompt"
// LLMModule publishes to "{Metadata.Name}.port.response"
```

From existing ChatPanel.razor:
```razor
// Currently calls ILLMService directly for chat
// Needs to be rewired to use ChatInputModule.SendMessageAsync
// and ChatOutputModule.OnMessageReceived for display
```

From WiringEngine (existing + Plan 02 extensions):
```csharp
// LoadConfiguration sets up EventBus subscriptions for port routing
// ExecuteAsync runs modules in topological order
// Now pushes status via SignalR
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Register modules in DI and wire ChatPanel to module ports</name>
  <files>
    src/OpenAnima.Core/DependencyInjection.cs
    src/OpenAnima.Core/Components/Shared/ChatPanel.razor
  </files>
  <action>
**DependencyInjection.cs** (or Program.cs — wherever services are registered):
1. Register all 4 modules as singletons (they maintain state):
   - `services.AddSingleton<LLMModule>()`
   - `services.AddSingleton<ChatInputModule>()`
   - `services.AddSingleton<ChatOutputModule>()`
   - `services.AddSingleton<HeartbeatModule>()`
2. Register them also as IModule for the module loader to discover:
   - `services.AddSingleton<IModule>(sp => sp.GetRequiredService<LLMModule>())`
   - Same for other 3 modules
3. Ensure IHubContext<RuntimeHub, IRuntimeClient> is injected into WiringEngine factory registration (if not already).
4. Call InitializeAsync on each module during startup (in WiringInitializationService or similar).
5. Register ports for each module in IPortRegistry during initialization (use PortDiscovery to scan attributes).

**ChatPanel.razor** — Rewire from direct ILLMService to module ports:
1. Inject ChatInputModule and ChatOutputModule instead of (or in addition to) ILLMService.
2. On user message submit: call `_chatInputModule.SendMessageAsync(message)` instead of calling ILLMService directly.
3. Subscribe to `_chatOutputModule.OnMessageReceived` to display LLM responses.
4. In OnInitializedAsync, subscribe: `_chatOutputModule.OnMessageReceived += HandleResponse`
5. In Dispose, unsubscribe: `_chatOutputModule.OnMessageReceived -= HandleResponse`
6. HandleResponse: add response to chat messages list, call InvokeAsync(StateHasChanged).
7. Keep existing chat UI layout and styling — only change the data flow path.
8. The actual routing (ChatInput→LLM→ChatOutput) happens through WiringEngine's EventBus subscriptions when a wiring configuration with these connections is loaded.

**Important:** The chat flow now requires a wiring configuration to be loaded that connects ChatInputModule.userMessage → LLMModule.prompt and LLMModule.response → ChatOutputModule.displayText. Without this wiring, messages won't flow. The WiringInitializationService should load a default configuration that includes these connections.
  </action>
  <verify>
    <automated>cd /home/user/OpenAnima && dotnet build src/OpenAnima.Core/OpenAnima.Core.csproj --no-restore 2>&1 | tail -5</automated>
  </verify>
  <done>All 4 modules registered in DI. ChatPanel uses ChatInputModule for sending and ChatOutputModule for receiving. Build succeeds.</done>
</task>

<task type="auto">
  <name>Task 2: Create E2E integration test for ChatInput→LLM→ChatOutput wiring</name>
  <files>
    tests/OpenAnima.Tests/Integration/E2EWiringTests.cs
  </files>
  <action>
Create integration test that verifies the full wiring pipeline:

1. Set up real DI container with: EventBus, PortRegistry, WiringEngine, all 4 modules (use mock ILLMService that returns a fixed response).
2. Initialize all modules (call InitializeAsync).
3. Register ports for each module via PortDiscovery.
4. Create a WiringConfiguration with:
   - 3 nodes: ChatInputModule, LLMModule, ChatOutputModule
   - 2 connections: ChatInput.userMessage → LLM.prompt, LLM.response → ChatOutput.displayText
5. Load configuration into WiringEngine.
6. Subscribe to ChatOutputModule.OnMessageReceived with TaskCompletionSource.
7. Call ChatInputModule.SendMessageAsync("Hello").
8. Assert: TaskCompletionSource completes within 5 seconds.
9. Assert: ChatOutputModule.LastReceivedText contains the mock LLM response.
10. Assert: LLMModule.GetState() == ModuleExecutionState.Completed.

Use real EventBus (not mocks) per project pattern. Fresh services per test. Temp directory for config files.
  </action>
  <verify>
    <automated>cd /home/user/OpenAnima && dotnet test tests/OpenAnima.Tests/ --filter "FullyQualifiedName~E2EWiringTests" --no-restore -v minimal 2>&1 | tail -10</automated>
  </verify>
  <done>E2E test passes: message flows ChatInput→LLM→ChatOutput through EventBus port routing. Module states transition correctly. Mock LLM response arrives at ChatOutputModule.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: Visual checkpoint — verify complete module wiring and status indicators</name>
  <files>N/A</files>
  <action>
Human verifies the complete Phase 14 implementation:
- Module wiring produces working chat conversation (v1.2 parity)
- Editor displays real-time module status with colored borders
- Error nodes show detail popup on click
  </action>
  <verify>
    1. Run `dotnet run --project src/OpenAnima.Core` to start the application
    2. Open browser to the editor page
    3. Verify nodes show status indicators (gray circles when idle)
    4. Open the chat panel and send a message
    5. Verify the message flows through the wiring: ChatInput→LLM→ChatOutput
    6. Verify you receive an LLM response (identical to v1.2 behavior)
    7. Observe node borders change color during execution (green flash for running/completed)
    8. If any module errors, verify the node border turns red and clicking shows error details
  </verify>
  <done>User confirms: chat works through module wiring, status indicators visible, error popup functional. Type "approved" or describe issues.</done>
</task>

</tasks>

<verification>
- `dotnet build` succeeds
- `dotnet test --filter "E2EWiringTests"` — E2E integration test passes
- `dotnet test` — all existing tests still pass (no regressions)
- Chat conversation works through module wiring (v1.2 parity)
- Editor shows real-time module status
</verification>

<success_criteria>
- All 4 modules registered in DI and initialized at startup
- ChatPanel sends messages through ChatInputModule, receives through ChatOutputModule
- WiringEngine routes data between connected module ports
- E2E test proves ChatInput→LLM→ChatOutput pipeline works
- User confirms visual checkpoint: chat works, status indicators visible
</success_criteria>

<output>
After completion, create `.planning/phases/14-module-refactoring-runtime-integration/14-03-SUMMARY.md`
</output>
